{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5jRJR5XYWLSh"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import io\n","from tensorflow.python.keras import Model\n","from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Concatenate, Dropout, Lambda, Reshape, AveragePooling2D, Flatten, Dense, Add, UpSampling2D\n","import tensorflow.compat.v2 as tf\n","tf.enable_v2_behavior()\n","\n","import glob\n","import os\n","import pickle\n","import segmentation_models as sm\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ModelCheckpoint, Callback, CSVLogger, TensorBoard\n","from tensorflow.python import keras\n","\n","from tensorflow.python.keras import layers\n","\n","import tensorflow_probability as tfp"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"10zbdMu296Nh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCKBVWWjWLSk"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cTRdog_WLSl"},"outputs":[],"source":["image_feature_description = {\n","  'image': tf.io.FixedLenFeature([], tf.string),\n","  'label': tf.io.FixedLenFeature([], tf.string),\n","  }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7ZqsF5c9xn4"},"outputs":[],"source":["def _parse_image_function(example_proto):\n","    features = tf.io.parse_single_example(example_proto, image_feature_description)\n","    image = tf.io.decode_raw(features['image'], tf.float32)\n","    image.set_shape([16 * 224 * 224])\n","    image = tf.reshape(image, [224, 224,16])\n","\n","    tensor1 = tf.convert_to_tensor((np.ones((224,224,16))*np.array([[0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,\n","                                                                   0.02,0.02,0.02,0.02, 0.03, 0.01]])).astype(np.float32))\n","    tensor2 = tf.convert_to_tensor((np.ones((224,224,16))*np.array([[0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0]])).astype(np.float32))\n","\n","    image = tf.multiply(image, tensor1)\n","    image = tf.add(image, tensor2)\n","\n","    label = tf.io.decode_raw(features['label'], tf.float32)\n","    label.set_shape([1 * 224 * 224])\n","    label = tf.reshape(label, [ 224, 224,1])\n","\n","    return image[:,:,:15], label   # image[:,:,10:15] = S1 + NL, image[:,:,:15] = S2 + S1 + NL,"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5o-4d0WD9xn4"},"outputs":[],"source":["def read_dataset(epochs, batch_size, filenames):\n","\n","    dataset = tf.data.TFRecordDataset(filenames)\n","\n","    image_feature_description = {\n","        'image': tf.io.FixedLenFeature([], tf.string),\n","        'label': tf.io.FixedLenFeature([], tf.string),\n","    }\n","\n","    dataset = dataset.map(_parse_image_function)\n","    dataset = dataset.prefetch(64)\n","    #dataset = dataset.repeat(epochs)\n","    #dataset = dataset.shuffle(buffer_size=2 * batch_size)\n","    dataset = dataset.batch(batch_size, drop_remainder=True)\n","\n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ei5b3d1J9xn4"},"outputs":[],"source":["ListBackbone = ['inceptionv3','vgg19','resnet18','mobilenetv2']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnJiNzvQ9xn4"},"outputs":[],"source":["ListBackbone = ['inceptionv3','vgg19','resnet18']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuckNpM49xn4"},"outputs":[],"source":["ListBackbone = ['mobilenetv2']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35k6qcs99xn5"},"outputs":[],"source":["Berlin = '/dir/MultiBands2//Test00.tfrecords'\n","London = '/dir/MultiBands2//Test01.tfrecords'\n","testset = London\n","Len_test = sum(1 for _ in tf.data.TFRecordDataset(testset))\n","test_dataset = read_dataset(1, 1, testset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6_Tif9v9xn5","outputId":"315b990c-37be-4df6-c0d6-6652285d61c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_MSE= 14.856551260858218\n","test_R= 1.5996266746355856\n","test_MSE= 16.956415610668714\n","test_R= 1.683934767158241\n","test_MSE= 15.098048076734576\n","test_R= 1.7393267422550045\n","test_MSE= 15.13943646558708\n","test_R= 1.6735123915123795\n","test_MSE= 15.501804746936264\n","test_R= 1.734999574697693\n"]}],"source":["textfile = open('/dir/MultiBands2/Results/Unet_S1_NL_Berlin_MAE.csv', 'w')\n","textfile.write( 'Backbone/Fold')\n","\n","for i in range(5) :\n","    textfile.write( ' , ')\n","    textfile.write( 'Fold'+str(i) )\n","textfile.write('\\n')\n","textfile.close()\n","\n","textfile2 = open('/dir/MultiBands2/Results/Unet_S1_NL_Berlin_MSE.csv', 'w')\n","textfile2.write( 'Backbone/Test')\n","\n","for i in range(5) :\n","    textfile2.write( ' , ')\n","    textfile2.write( 'Fold'+str(i) )\n","textfile2.write('\\n')\n","textfile2.close()\n","\n","for backbone in ListBackbone:\n","    textfile = open('/dir/MultiBands2/Results/Unet_S1_NL_Berlin_MAE.csv', 'a')\n","    textfile2 =  open('/dir/MultiBands2/Results/Unet_S1_NL_Berlin_MSE.csv', 'a')\n","    textfile.write( backbone + ' , ')\n","    textfile2.write( backbone + ' , ')\n","\n","\n","    for i in range(5):\n","        model = tf.keras.models.load_model('/dir/MultiBands2/Models/Unet_' + backbone + '_S1_NL_' + str(i))\n","        model.compile( loss='mean_squared_error', optimizer='adam')\n","\n","        Y_predict = np.zeros((Len_test,224,224))\n","        Y_train =  np.zeros((Len_test,224,224))\n","        count = 0\n","        for p, l in test_dataset.take(Len_test): # Takes 1 batch\n","            y_hat = model(p)\n","            y_r = l\n","\n","            Y_predict[count,:,:] = y_hat[:,:,:,0].numpy()\n","            Y_train[count,:,:] = y_r[:,:,:,0].numpy()\n","\n","            count = count + 1\n","\n","        test_MSE = mean_squared_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        test_R = mean_absolute_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        print('test_MSE= '+ str(test_MSE))\n","        print('test_R= '+ str(test_R))\n","\n","        textfile.write( str(test_R) + ' , ')\n","        textfile2.write( str(test_MSE) + ' , ')\n","\n","    textfile.write('\\n')\n","    textfile2.write('\\n')\n","    textfile.close()\n","    textfile2.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzLkE2yP9xn6","outputId":"cd1e74b2-53fc-43cc-b397-3e5aa252c549"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_MSE= 12.875762260275227\n","test_R= 1.4809710204837903\n","test_MSE= 13.031059113776019\n","test_R= 1.4603006160191432\n","test_MSE= 12.492405948801265\n","test_R= 1.4873980898506869\n","test_MSE= 14.330973345812653\n","test_R= 1.5222997800242815\n","test_MSE= 13.113847689230274\n","test_R= 1.5402506934175377\n"]}],"source":["textfile = open('/dir/MultiBands2/Results/Unet_S1_S2_NL_Berlin_MAE.csv', 'w')\n","textfile.write( 'Backbone/Fold')\n","\n","for i in range(5) :\n","    textfile.write( ' , ')\n","    textfile.write( 'Fold'+str(i) )\n","textfile.write('\\n')\n","textfile.close()\n","\n","textfile2 = open('/dir/MultiBands2/Results/Unet_S1_S2_NL_Berlin_MSE.csv', 'w')\n","textfile2.write( 'Backbone/Test')\n","\n","for i in range(5) :\n","    textfile2.write( ' , ')\n","    textfile2.write( 'Fold'+str(i) )\n","textfile2.write('\\n')\n","textfile2.close()\n","\n","for backbone in ListBackbone:\n","    textfile = open('/dir/MultiBands2/Results/Unet_S1_S2_NL_Berlin_MAE.csv', 'a')\n","    textfile2 =  open('/dir/MultiBands2/Results/Unet_S1_S2_NL_Berlin_MSE.csv', 'a')\n","    textfile.write( backbone + ' , ')\n","    textfile2.write( backbone + ' , ')\n","\n","\n","    for i in range(5):\n","        model = tf.keras.models.load_model('/dir/MultiBands2/Models/Unet_' + backbone + '_S1_S2_NL_' + str(i))\n","        model.compile( loss='mean_squared_error', optimizer='adam')\n","\n","        Y_predict = np.zeros((Len_test,224,224))\n","        Y_train =  np.zeros((Len_test,224,224))\n","        count = 0\n","        for p, l in test_dataset.take(Len_test): # Takes 1 batch\n","            y_hat = model(p)\n","            y_r = l\n","\n","            Y_predict[count,:,:] = y_hat[:,:,:,0].numpy()\n","            Y_train[count,:,:] = y_r[:,:,:,0].numpy()\n","\n","            count = count + 1\n","\n","        test_MSE = mean_squared_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        test_R = mean_absolute_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        print('test_MSE= '+ str(test_MSE))\n","        print('test_R= '+ str(test_R))\n","\n","        textfile.write( str(test_R) + ' , ')\n","        textfile2.write( str(test_MSE) + ' , ')\n","\n","    textfile.write('\\n')\n","    textfile2.write('\\n')\n","    textfile.close()\n","    textfile2.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0ykPj9t9xn6","outputId":"29cbe998-9a0c-4088-90b2-24881e70850a"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_MSE= 11.461108121002528\n","test_R= 1.6911863505698816\n","test_MSE= 11.848014748281626\n","test_R= 1.7081063047292764\n","test_MSE= 11.745130366831722\n","test_R= 1.8831637964039138\n","test_MSE= 11.583060725603861\n","test_R= 1.7664039327487573\n","test_MSE= 11.60820141748073\n","test_R= 1.7948574344487374\n"]}],"source":["textfile = open('/dir/MultiBands2/Results/Unet_S1_NL_London_MAE.csv', 'w')\n","textfile.write( 'Backbone/Fold')\n","\n","for i in range(5) :\n","    textfile.write( ' , ')\n","    textfile.write( 'Fold'+str(i) )\n","textfile.write('\\n')\n","textfile.close()\n","\n","textfile2 = open('/dir/MultiBands2/Results/Unet_S1_NL_London_MSE.csv', 'w')\n","textfile2.write( 'Backbone/Test')\n","\n","for i in range(5) :\n","    textfile2.write( ' , ')\n","    textfile2.write( 'Fold'+str(i) )\n","textfile2.write('\\n')\n","textfile2.close()\n","\n","for backbone in ListBackbone:\n","    textfile = open('/dir/MultiBands2/Results/Unet_S1_NL_London_MAE.csv', 'a')\n","    textfile2 =  open('/dir/MultiBands2/Results/Unet_S1_NL_London_MSE.csv', 'a')\n","    textfile.write( backbone + ' , ')\n","    textfile2.write( backbone + ' , ')\n","\n","\n","    for i in range(5):\n","        model = tf.keras.models.load_model('/dir/MultiBands2/Models/Unet_' + backbone + '_S1_NL_' + str(i))\n","        model.compile( loss='mean_squared_error', optimizer='adam')\n","\n","        Y_predict = np.zeros((Len_test,224,224))\n","        Y_train =  np.zeros((Len_test,224,224))\n","        count = 0\n","        for p, l in test_dataset.take(Len_test): # Takes 1 batch\n","            y_hat = model(p)\n","            y_r = l\n","\n","            Y_predict[count,:,:] = y_hat[:,:,:,0].numpy()\n","            Y_train[count,:,:] = y_r[:,:,:,0].numpy()\n","\n","            count = count + 1\n","\n","        test_MSE = mean_squared_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        test_R = mean_absolute_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        print('test_MSE= '+ str(test_MSE))\n","        print('test_R= '+ str(test_R))\n","\n","        textfile.write( str(test_R) + ' , ')\n","        textfile2.write( str(test_MSE) + ' , ')\n","\n","    textfile.write('\\n')\n","    textfile2.write('\\n')\n","    textfile.close()\n","    textfile2.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJRLmRzj9xn6","outputId":"16c656bd-9fa9-4114-f24b-3dc878058c54"},"outputs":[{"name":"stdout","output_type":"stream","text":["test_MSE= 10.346511586504464\n","test_R= 1.5695600322010852\n","test_MSE= 10.555392778170848\n","test_R= 1.5823340145600455\n","test_MSE= 10.38797545881581\n","test_R= 1.623212949852897\n","test_MSE= 10.945781224253379\n","test_R= 1.5688647302819079\n","test_MSE= 10.540995077274275\n","test_R= 1.6152345194930706\n"]}],"source":["\n","textfile = open('/dir/MultiBands2/Results/Unet_S1_S2_NL_London_MAE.csv', 'w')\n","textfile.write( 'Backbone/Fold')\n","\n","for i in range(5) :\n","    textfile.write( ' , ')\n","    textfile.write( 'Fold'+str(i) )\n","textfile.write('\\n')\n","textfile.close()\n","\n","textfile2 = open('/dir/MultiBands2/Results/Unet_S1_S2_NL_London_MSE.csv', 'w')\n","textfile2.write( 'Backbone/Test')\n","\n","for i in range(5) :\n","    textfile2.write( ' , ')\n","    textfile2.write( 'Fold'+str(i) )\n","textfile2.write('\\n')\n","textfile2.close()\n","\n","for backbone in ListBackbone:\n","    textfile = open('/dir/MultiBands2/Results/Unet_S1_S2_NL_London_MAE.csv', 'a')\n","    textfile2 =  open('/dir/MultiBands2/Results/Unet_S1_S2_NL_London_MSE.csv', 'a')\n","    textfile.write( backbone + ' , ')\n","    textfile2.write( backbone + ' , ')\n","\n","\n","    for i in range(5):\n","        model = tf.keras.models.load_model('/dir/MultiBands2/Models/Unet_' + backbone + '_S1_S2_NL_' + str(i))\n","        model.compile( loss='mean_squared_error', optimizer='adam')\n","\n","        Y_predict = np.zeros((Len_test,224,224))\n","        Y_train =  np.zeros((Len_test,224,224))\n","        count = 0\n","        for p, l in test_dataset.take(Len_test): # Takes 1 batch\n","            y_hat = model(p)\n","            y_r = l\n","\n","            Y_predict[count,:,:] = y_hat[:,:,:,0].numpy()\n","            Y_train[count,:,:] = y_r[:,:,:,0].numpy()\n","\n","            count = count + 1\n","\n","        test_MSE = mean_squared_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        test_R = mean_absolute_error(Y_train.reshape(Len_test*224*224), Y_predict.reshape(Len_test*224*224))\n","        print('test_MSE= '+ str(test_MSE))\n","        print('test_R= '+ str(test_R))\n","\n","        textfile.write( str(test_R) + ' , ')\n","        textfile2.write( str(test_MSE) + ' , ')\n","\n","    textfile.write('\\n')\n","    textfile2.write('\\n')\n","    textfile.close()\n","    textfile2.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6upHPqK9xn7"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":0}